{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KG Agent with Langchain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Determining how accurate LLMs are at navigating a KG similar to the ones of a website\n",
    "- Determining what inputs are necessary for that KG\n",
    "\n",
    "Testing langchainâ€™s ability to have agents as tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.schema import AgentAction, AgentFinish, HumanMessage\n",
    "from langchain.prompts import BaseChatPromptTemplate\n",
    "from langchain import SerpAPIWrapper, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from typing import List, Union, Callable\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from KG_tools import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be replaced by real web page parsing function. Each node description contains its child node description, too. It can be seen as MDP process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node(current_node, filepath=\"data/KG.xlsx\"):\n",
    "    child_node_name_list = []\n",
    "    df = pd.read_excel(filepath)\n",
    "\n",
    "    if current_node in df['node'].tolist():\n",
    "        row = df.loc[df['node'] == current_node]\n",
    "        if str(row['next_node'].tolist()[0]) != 'nan':\n",
    "            child_node_name_list = row['next_node'].tolist()[0].split(', ')\n",
    "    else:\n",
    "        print(\"NO CURRENT NODE\")\n",
    "\n",
    "    child_node_list = []\n",
    "    for i, child_node in enumerate(child_node_name_list):\n",
    "        row = df.loc[df['node'] == child_node]\n",
    "        description = row['description'].tolist()[0] + \" If you select this element, then the element interactable in the next webpage is: \"\n",
    "\n",
    "        if ', ' in str(row['next_node'].tolist()[0]):\n",
    "            for grandchild_node in row['next_node'].tolist()[0].split(', '):\n",
    "                description += '\\n  Element Name: ' + grandchild_node + ' Element Description: ' + df.loc[df['node'] == grandchild_node]['description'].tolist()[0]\n",
    "\n",
    "        elif str(row['next_node'].tolist()[0]) != 'nan':\n",
    "            description += '\\n  Element Name: ' + row['next_node'].tolist()[0] + ' Element description: '+ df.loc[df['node'] == row['next_node'].tolist()[0]]['description'].tolist()[0]\n",
    "        else:\n",
    "            description += \"Nothing.\"\n",
    "        \n",
    "        child_node_list.append(Tool(name=child_node, func=eval(child_node), description=description, return_direct=True))\n",
    "    \n",
    "    return child_node_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test this state transition function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_node('disable')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our main prompt for agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PROMPT = \"\"\"You are a web interaction AI and you have all interactable elements of the current web page. Each element has a name and a description.\n",
    "HISTORY is a time series of all the elements you have selected from the initial page to the current page so far.\n",
    "USER GOAL is the web interaction that the user wants to achieve, and you have to achieve it step by step by selecting web elements.\n",
    "Given USER GOAL and HISTORY, you need to choose the element from ELEMENTS that are most likely to achieve the USER GOAL.\n",
    "\n",
    "The USER GOAL is: \n",
    "{input}\n",
    "\n",
    "The HISTORY is: {history}\n",
    "\n",
    "The current webpage ELEMENTS:\n",
    "{tools}\n",
    "\n",
    "When you determine that an element is selected, if the element is a clickable element (a button for example), then the input to that element should be None. \n",
    "If it is an input box element, then the input to the tool should be the text content you want to enter.\n",
    "\n",
    "If you think the USER GOAL is finally done at current webpage (comparing the HISTORY and USER GOAL to make sure of that), then you must choose nothing and return \"FINISH\" directly.\n",
    "You should only output selected element name, and the element's input if needed. Your Output:\n",
    "ELEMENT NAME:\n",
    "ELEMENT INPUT:\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt template used for formatting main prompt every step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStepPromptTemplate(BaseChatPromptTemplate):\n",
    "    template: str\n",
    "    tools: List[Tool]\n",
    "    \n",
    "    def format_messages(self, **kwargs) -> str:\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        history = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            history += '\\nOBSERVATION: ' + observation # action.log\n",
    "        kwargs[\"history\"] = history\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        formatted = self.template.format(**kwargs)\n",
    "        return [HumanMessage(content=formatted)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output parser makes LLM's output `AgentAction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStepOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        if \"FINISH\" in llm_output:\n",
    "            return None\n",
    "            # return AgentFinish(return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()}, log=llm_output)\n",
    "\n",
    "        regex = r\"ELEMENT\\s*\\d*\\s*NAME\\s*\\d*\\s*:(.*?)\\nELEMENT\\s*\\d*\\s*INPUT\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            return None\n",
    "            # raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output.replace('\\n', ' '))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some configurations about GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"config/config.yaml\", 'r') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = config['OPENAI_API_KEY']\n",
    "TEMPERATURE = config['TEMPERATURE']\n",
    "MODEL_NAME = config['MODEL_NAME']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing our method with dataset in `data/dataset.xlsx` now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/dataset.xlsx')\n",
    "llm = ChatOpenAI(model_name=MODEL_NAME, temperature=TEMPERATURE)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    # initialization\n",
    "    node = (AgentAction(tool=\"start\", tool_input=\"None\", log=\"\"), \"Start.\")\n",
    "    node_history = [node]\n",
    "    user_goal = row['user_query']\n",
    "    print(\"USER GOAL:\", user_goal)\n",
    "\n",
    "    while True:\n",
    "        node_list = get_node(node[0].tool)\n",
    "        if not len(node_list):\n",
    "            print(\"ARRIVED END STATE\")\n",
    "            break\n",
    "\n",
    "        prompt = OneStepPromptTemplate(template=MAIN_PROMPT,\n",
    "                                        tools=node_list,\n",
    "                                        input_variables=[\"input\", \"intermediate_steps\"]\n",
    "                                    )\n",
    "        output_parser = OneStepOutputParser()\n",
    "        llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "        agent = LLMSingleActionAgent(llm_chain=llm_chain, \n",
    "                                     stop=[\"FINISH\"], \n",
    "                                     output_parser=output_parser,\n",
    "                                     allowed_tools=[tool.name for tool in node_list]\n",
    "                                    )\n",
    "\n",
    "        node = agent.plan(input=user_goal, intermediate_steps=node_history)\n",
    "\n",
    "        if node == None:\n",
    "            print(\"DONE\")\n",
    "            break \n",
    "\n",
    "        print(\"ACTION:\", node)\n",
    "        node = (node, f\"You selected ELEMENT {node.tool} from {[n.name for n in node_list]}.\")\n",
    "        node_history.append(node)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What to be done\n",
    "- web parser + selenium tool functions - See `building_KG.ipynb`\n",
    "- (state, action) pair or using GPT for summrization  `DONE`\n",
    "- Adding thoughts  `DONE`\n",
    "- stop word problem `DONE`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
