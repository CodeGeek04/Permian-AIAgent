{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web Parser (1 step)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml, os\n",
    "\n",
    "with open(\"config/config.yaml\", 'r') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = config['OPENAI_API_KEY']\n",
    "USER_DATA_DIR = config['USER_DATA_DIR']\n",
    "MAIN_URL = config['MAIN_URL']\n",
    "MODEL_NAME = config['MODEL_NAME']\n",
    "TEMPERATURE = config['TEMPERATURE']\n",
    "WEBSITE_USERNAME = config['WEBSITE_USERNAME']\n",
    "WEBSITE_PASSWORD = config['WEBSITE_PASSWORD']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start webdriver with main url. Then finish the login process automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-31a0b19afb0d>:10: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_options=options)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "if USER_DATA_DIR:\n",
    "    options.add_argument(f\"user-data-dir={USER_DATA_DIR}\")\n",
    "    # options.add_argument(\"--headless\")\n",
    "\n",
    "driver = webdriver.Chrome(chrome_options=options)\n",
    "driver.maximize_window()\n",
    "driver.get(MAIN_URL)\n",
    "driver.implicitly_wait(2)\n",
    "\n",
    "driver.find_element(By.CSS_SELECTOR, 'a.nav-link.login.w-nav-link').click()\n",
    "driver.find_element(By.CSS_SELECTOR, \"input[name='email']\").clear()\n",
    "driver.find_element(By.CSS_SELECTOR, \"input[name='email']\").send_keys(WEBSITE_USERNAME)\n",
    "driver.find_element(By.CSS_SELECTOR, \"input[name='password']\").send_keys(WEBSITE_PASSWORD)\n",
    "driver.find_element(By.CSS_SELECTOR, 'button.btn.btn-success').click()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A html cleaning function. Used for every step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def html_cleaner(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    elements_with_style = soup.select('[style]')\n",
    "    for element in elements_with_style:\n",
    "        del element['style']\n",
    "    \n",
    "    for tag in soup(['script', 'style', 'noscript', 'circle', 'meta', 'path']):\n",
    "        tag.extract()\n",
    "\n",
    "    # for div in soup.find_all('div'):\n",
    "    #     del div['tabindex', 'data-test', 'aria-hidden', 'role']\n",
    "\n",
    "    clean_html_content = soup.prettify()\n",
    "    with open('data/html_content.html', 'w') as f:\n",
    "        f.write(str(clean_html_content))\n",
    "        \n",
    "    return clean_html_content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Token counting function. Used for segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using LLMChain with this prompt. Notice that this prompt still needs more refinement, and we add some instructions for instantly web HTML specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEBPAGE_TEMPLATE = \"\"\"Given the following HTML script, you need to extract from it some elements of the webpage that can be interacted with.\n",
    "An interactive web element is a button or a text input box, and you need to make full use of your knowledge of html to determine this. \n",
    "\n",
    "If there's a <title> or <h3> <h4> <h5> <h6> label, you must add that to element list.\n",
    "If there's a <li> label with 'sidebar_wrapper_XXX' as its id, you must add that to element list.\n",
    "\n",
    "Your output format should be [{{\"element_name\": \"...\", \"element_description\": \"...\", \"element_css\": \"...\"}}, {{\"element_name\": \"...\", \"element_description\": \"...\", \"element_css\": \"...\"}}, ...]\n",
    "Element name should preferably be some text attribute, if not exist, a reasonable name should be inferred from other attributes like class / id / html structure. \n",
    "Element description should describe what the element does and where it is located, or the function of clicking / typing on it.\n",
    "Element css should be its css path used for locating elements using selenium.\n",
    "\n",
    "HTML script is:\n",
    "{html_snippet}\n",
    "\n",
    "Your output:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(model_name=MODEL_NAME, temperature=TEMPERATURE)\n",
    "prompt = PromptTemplate(input_variables=[\"html_snippet\"], template=WEBPAGE_TEMPLATE)\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTML into chunks. Before running this, you can go to any page you want manually. Then get the element tool list recursively. This will take some time for every loop.\n",
    "\n",
    "`TODO`: Using langchain text splitter and its overlap setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def html_parser(all_node, driver, chain):\n",
    "    html = html_cleaner(driver.page_source) # using html_cleaner\n",
    "    chunk_num = int(num_tokens_from_string(str(html), model_name=\"gpt-4\") / 4000)\n",
    "    html_lines = html.split('\\n')\n",
    "    chunks = [html_lines[i:i+int(len(html_lines) / chunk_num)] for i in range(0, len(html_lines), int(len(html_lines) / chunk_num))]\n",
    "    chunks = ['\\n'.join(chunk) for chunk in chunks]\n",
    "\n",
    "    for i in tqdm(range(len(chunks))):\n",
    "        try:\n",
    "            new_node_list = eval(chain.run(chunks[i]))\n",
    "            \n",
    "            for new_node in new_node_list:\n",
    "                new_node[\"child_element\"] = \"\"\n",
    "                new_node[\"element_url\"] = driver.current_url\n",
    "                if new_node not in all_node:\n",
    "                    all_node.append(new_node)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "    return all_node"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually traverse the seven buttons in the left column as nodes in turn, and then build the whole tree manually in different csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sidebar_nodes = [\"accounts\", \"campaigns\", \"analytics\", \"unibox\", \"settings\", \"accelerator\"] # all sidebar elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [02:44<00:00, 41.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid syntax (<string>, line 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [02:39<00:00, 53.18s/it]\n",
      "100%|██████████| 1/1 [01:22<00:00, 82.98s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "for node in sidebar_nodes:\n",
    "    driver.find_element(By.CSS_SELECTOR, f'li#sidebar_wrapper_{node}').click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    all_node = []\n",
    "    all_node = html_parser(all_node, driver=driver, chain=chain)\n",
    "\n",
    "    df = pd.DataFrame(all_node)\n",
    "    df.to_excel(f\"data/{node}_KG.xlsx\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TODO`: This part is not finished, don't play with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_script(\"window.scrollBy(0,1000)\")\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "# whether we're at the bottom of page\n",
    "while True:\n",
    "    driver.execute_script(\"window.scrollBy(0, 1000)\")\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "driver.back() # get back to last page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
